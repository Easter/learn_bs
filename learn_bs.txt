Beautiful Soup学习笔记：
字符串前加u代表unicode编码；
1：Tag:标签：：
例如：<b class="boldest">Extremely bold</b>
	1:tag.name :: 
		# u'b'
	2:tag.attribute ::即指tag的属性
		本例中有class属性，值为“blodest”
		tag['calss']:
		# u'boldest'
		#也可以直接‘点’取所有属性以字典形式展示
		tag.arrts
		#{u'class':u'boldest'}
		tag的属性可以被添加，删除或修改，tag的属性操作与字典一样
		tag['calss'] = 'verybold'
		tag['id'] = 1
		tag:
		# <b class="vreyblod" id="1">Extremely bold</b>
		del tag['calss']
		del tag['id']
		2.1:多值属性
			2.1.1：
				html4定义了一系列包含多个值的属性，在html5中移除了一些，却增加了更多，最常见的多值属性是classhtml4定义了一系列包含多个值的属性，在html5中移除了一些，却增加了更多，最常见的多值属性是class
				///(一个tag可以有多个CSS的class.)
				css_soup = BeautifulSoup('<p class="body strikeout"></p>')
				css_soup.p['class']
				# ["body","strikeout"] 返回的形式为list相当于字典里的值为list形式储存
					//但是仅适用于多值属性 非多值属性一律以字符串形式返回
				css_soup = BeautifulSoup('<p class="body"></p>')
				css_soup.p['calss']
				# ["body"]
			2.1.2：
				如果一个属性看起来好像有多个值，但在任何版本的HTML中都没有被定义为多值属性，如果一个属性看起来好像有多个值，但在任何版本的HTML中都没有被定义为多值属性，
				///那么Beautiful Soup会将这个属性作为字符串返回
				id_soup = BeautifulSoup('<p id="my id"></p>')
				id_soup.p['id']
				# "my id"
			2.1.3：
				将tag转换成字符串时，多值属性会合并为一个值
				rel_soup = BeautifulSoup('<p>Back to the<a rel="index">homepage</a><p>')
				rel_soup.a[rel]
				# [index]
				rel_soup.a['rel']=['index','contents']
				print rel_soup.p
				# <p>Back to the<a rel='index content'>homepage</a></p>
	
2：可以遍历的字符串：：
	字符串常被包含在tag内。BeautifulSoup用NavigableString 类包装tag中的字符串
	1:tag.string
	# u'Extremely bold'
	type(tag.string)
	# <class ''bs4.element.NavigableString>
	通过unicode()方法直接将NavigableString对象转换成Unicode字符串：
	unicode_string = unicode(tag.string)
	unicode_string
	# u'Extremely bold'
	type(unicode_string)
	# <type 'unicode'>
	2:tag中包含的字符串不能被编辑，但是可以被替换成其他的字符串，用replace_with()方法：
		tag.string.replace_with("No longer bold")
		tag.string
		# No longer bold
		# tag中字符串不支持.contents或.string属性或find()
3:BeautifulSoup:
	BeautifulSoup对象表示的是一个文档的全部内容，大部分时候，可以把它当作Tag对象，它支持遍历文档树和搜索文档树中描述的大部分方法
	1:BeautifulSoup.name
	# u'document'
	注释及特殊字符串
	2:Tag,NavigableString,BeautifulSoup几乎覆盖了html和lxml的所有内容，但是还有一些特殊对象。容易让人担心的内容是文档的注释部分：
		markup = "<b><!--Hey,buddy.Want to buy a used parser?--></b>"
		soup = BeautifulSoup(markup)
		comment = soup.b.string
		type(comment)
		# <class 'bs4.element.Comment'>
		comment
		# 'Hey,buddy,Want to buy a used parser?'
	3:但是当他出现在HTML文档中时，Comment对象会使用特殊的格式输出//注释形式的字符串都以Commend类型呈现在HTM中
		print(soup.b.prettify)
		#<b>
		<!--Hey,buddy.Want to buy a used parser?-->
		</b>
		BeautifulSoup定义的其他类型都可能会出现在XML的文档中，BeautifulSoup中文文档可查//都是NavigableString的子类
	
4:遍历文档树：：
爱丽丝梦游仙境文档当作例子
html_doc = """
<html><head><title>The Dormouse's story</title></head>
    <body>
<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""

from bs4 import BeautifulSoup
soup = BeautifulSoup(html_doc, 'html.parser')
	4.1:子节点：
		一个tag可能包含多个字符串或其他的Tag,这些都是这个Tag的子节点（字符串也都是子节点）
		！！！Beautiful Soup中的字符串不支持这些属性，因为字符串没有子节点
	4.2:tag的名字：
		4.2.1操作文档树最简单的方法是告诉它你想获取的tag的name,如果想获取head标签只要用soup.head：
			soup.head
			# <head><title>The Dormouse's story</title></head>
			soup.title
			# <title>The Dormouse's story</title>
		4.2.1下面的代码可以获取<body>标签中的第一个<b>标签：：
			soup.body.b
			# <b>The Dormouse's story</b>
		4.2.3通过点属性的方式获取的只是当前名字的第一个tag
			soup.a
			# <a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>
		4.2.4：如果想要获取所有的a标签，或是通过名字得到比一个tag更多内容时，就需要用到Searching the tree 中描述的放法，例如：fing_all()
			soup.find_all(a)
			[<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
			 <a href="http://example.com/lacie" class="sister" id="link2">Lacie</a>
			 <a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>]
			 #find_all()以list形式返回搜索到的所有标签
		4.2.5：.contents和.children
			1:.contents
				tag的.contents属性可以将tag的子节点以列表的形式输出
				head_tag = soup.head
				head_tag
				# <head><title>The Dormouse's story</title></head>
				
				head_tag.contents:
				# [<title>The Dormouse's story</title>]
				title_tag = head_tag.contents[0]#列表的第一个元素
				title_tag
				# <title>The Dormouse's story</title>
				title_tag.contents
				# [The Dormouse's story]
				BeautifulSoup对象本身一定会包含子节点，也就是说<html>标签也是<BeautifulSoup>对象的子节点
				len(soup.contents)
				# 1
				soup.contents[0].name
				# html
				字符串没有.contents属性，因为字符串没有子节点
				例如：text = title.contents[0]
					  text.contents
					  # AttributeError: "NavigableString" object has no attribute 'contents'
			2:.children
				通过tag的.children生成器，可以对tag的子节点进行循环：.contents也可以进行循环
				for child in title.children:
					print (child)
					# The Dormouse's story
		4.2.6：.descendants
			.contents和.children属性仅包含tag的直接子节点，例如head的直接子节点为title,
			但是title的直接子节点字符串"The Dormouse's story"也是head的子孙节点.descendants可以对tag的子孙节点进行递归循环
			for child in head_tag.descendants:
				print child
				# <title>The Dormouse's story</title>
				# The Dormouse's story
		4.2.7：.string
			如果一个tag只有一个NavigableString类型子节点，那么这个tag可以使用.string得到子节点：
			title.string
			# u'The Dormouse's story'
			如果一个tag仅有一个子节点，那么这个tag也可以使用.string方法，输出结果与当前唯一子节点的.string相同：
			head_tag.string
			# u'The Dormouse's story'
			但是如果tag包含了多个子节点，那么tag就无法确定调用哪个子节点的内容，.string的输出结果为None
		4.2.8: .strings和stripped_strings
			如果一个tag中包含了多个字符串，可以用.strings获取//返回类型未知，以后再考察
			for string in soup.stings:
			# u'soup中的所有字符串'
			但是得到的结果中有很多空格或空行，可以用stripped_strings去除多余的空白：
			for string in soup.stripped_strings:
			# u'没有空格的字符串'
	4.2：父节点：
		#继续分析文档树，每个tag或字符串都有父节点：被包含在某个tag中
		4.2.1：.parent
			title_tag = soup.title
			title_tag.parent
			# <head><title>The Dormouse's story</title></head>
			title_tag.string.parent
			# <title>The Dormouse's story</title>
			文档的顶层节点比如<html>的父节点是BeautifulSoup对象：
			html_tag = soup.html
			type(html_tag.parent)
			# <class 'bs4.BeautifulSoup'>
			BeautifulSoup对象的.parent是None
			print (soup.parent)
			# None
		4.2.2：.parents
			通过.parents属性可以递归到元素的所有父类节点，下面使用.parents方法遍历<a>标签到根节点的所有节点
			link = soup.a
			link
			# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
			for parent in link.parents:
				if parent is None:
					print parent
				else:
					print parent.name
			# p
			# body
			# html
			# [document]
			#并不会输出None并且len(list(link.parents))=4
		4.2.3：兄弟节点：
			看一个小例子：
				sibling_soup = BeautifulSoup("<a><b>text1</b><c>text2</c></a>","lxml")
			print (sibling_soup.prettify())
			# <html>
			#  <body>
			#   <a>
			#    <b>
			#     text1
			#    </b>
			#    <c>
			#     text2
			#    </c>
			#   </a>
			#  </body>
			# </html>
			<b>标签和<c>标签在同一层，是同一个元素的子节点，所以他们可以成为兄弟节点，一段文档以标准格式输出时,兄弟节点有相同的缩进级别.在代码中也可以使用这种关系.
			1：next_sibling 和 .previous_sibling
				在文档树中，用.next.sibling和.previous_sibling属性查询兄弟节点：
				sibling_soup.b.next_sibling
				# <c>text2</c>
				<b>标签有next.sibling属性，但是没有.previous_sibling属性，因为b标签在同级节点中是第一个，同理<c>标签没有.next_sibling属性
				例子中的text1和text2不是兄弟节点，因为它们的父节点不同
				实际文档中tag的.next_sibling和.previous_sibling属性通常是字符串或空白，“爱丽丝”为例：
				<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>
				<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a>
				<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>
				我们以为第一个<a>标签的.next_sibling是下一个<a>标签，措了，实际上是与第二个<a>标签的顿号和换行符
			2：.next_siblings和.previous_siblings
				.next_siblings和.previous_siblings可以对当前节点的兄弟节点进行迭代输出
				for sibling in soup.a.next_siblings:
					print repr(sibling)  # repr()返回一个对象的string格式
				# u',\n'
				# <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>
				# u' and\n'
				# <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>
				# u'; and they lived at the bottom of a well.'
				# None
				
				for sibling in soup.find(id="links").previous_siblings:
					print repr(sibling)
				# ' and\n'
				# <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>
				# u',\n'
				# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
				# u'Once upon a time there were three little sisters; and their names were\n'
				# None
		4.2.4：回退和前进：
			#看一下爱丽丝文档：
				<html><head><title>The Dormouse's story</title></head>
				<p class="title"><b>The Dormouse's story</b></p>
				HTML解析器把这些当作一连串的动作：打开"hrml"标签，打开head标签，打开title标签，添加一段字符串，关闭title标签，打开p标签，等等
			1：.next_element和.precious_element
				1.1:.next_element属性指向解析过程中下一个被解析的对象(字符串或者tag),结果可能与next_sibling相同
				last_a_tag = soup.find("a",id="link3")
				last_a_tag.next_.next_sibling
				# ';and they lived at the bottom of a well.'
				last_a_tag.next_element
				# u'Tillie'
				.precious_element和.next正好相反在这里就不多说了
			2：.next_elements和.precious_elementa
				通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样:
				for element in last_a_tag.next_elements:
					print(repr(element))
				# u'Tillie'
				# u';\nand they lived at the bottom of a well.'
				# u'\n\n'
				# <p class="story">...</p>
				# u'...'
				# u'\n'
				# None
5：搜索文档树：
Beautiful Soup定义了很多搜索方法，这里着重介绍两个：find()和find_all()，其他方法的参数和用法类似。举一反按
还是以“爱丽丝”文档作为例子：
html_doc = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""

from bs4 import BeautifulSoup
soup = BeautifulSoup(html_doc, 'html.parser')
使用find_all()类似的方法可以查到想要查找的文档内容
	5.1：过滤器：
		学习find_all之前，先学习一下过滤器的类型，过滤器贯穿搜索的整个API，过滤器可以被用在tag的name中，节点属性中，字符串或他们的混合中
		5.1.1：字符串：
			字符串是最简单的过滤器，在搜索方法中传入一个字符串参数，BeautifulSoup会搜索与字符串完整匹配的内容，下面的例子用于查找文档中所有的b标签
			soup.find_all('b')
			# [<b>The Dormouse's story</b>]
		5.1.2：正则表达式：
			传入正则表达式作为参数，Beautiful Soup会通过正则表达式的match()来匹配内容，下面例子找出所有以"b"开开头的标签，<body>和<b>标签都能被搜索到
			import re
			for tag in soup.find_all(re.compile("^b")):
				print (tag.name)
			# body
			# b
			下面的代码找出所有包含't'的标签：
			for tag in soup.find_all(re.compile("t"))
				print tag.name
			
			# html
			# title
		5.1.3：列表：
			传入列表参数，Beautiful Soup会将与列表中任意元素匹配的内容返回，下面的文档中找到所有的<a>标签与<b>标签：
			soup.find_all(["a","b"])
			# [<b>The Dormouse's story</b>,
			#  <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
			#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
			#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
		5.1.4：True
			True可以匹配任何值，下面的代码查到所有的tag，但是不会返回字符串节点
			for tag in soup.find_all(True)
				print(tag.nsme)
			# html
			# head
			# title
			# body
			# p
			# b
			# p
			# a
			# a
			# a
			# p
		5.1.5：方法：
			如果没有合适的过滤器，那么好可以定义一个方法，方法只接受一个参数，如果这个方法返回True,表示当前元素匹配并且被找到，如果不是则返回False
			def has_class_but_no_id(tag):
				return tag.hss_attr("class") and not tag.has_attr('id')
			1:将这个方法作为参数传入find_all()方法，将得到所有的<p>标签：
			soup.find_all(hss_class_but_no_id):
				# [<p class="title"><b>The Dormouse's story</b></p>,
				#  <p class="story">Once upon a time there were...</p>,
				#  <p class="story">...</p>]
			2:通过一个方法来过滤一类标签属性的时候, 这个方法的参数是要被过滤的属性的值, 而不是这个标签. 下面的例子是找出 href 属性不符合指定正则的 a 标签.
				def not_lacie(href):
					return href and not re.compile("lacie").search(href)
				soup.find_all(href=not_lacie)
				# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
				#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
			3:标签过滤方法可以使用复杂方法，下面的例子可以过滤出前后都有文字的标签：
			from bs4 import NavigableString
			def surrounded_by_strings(tag):
				return (isinstance(tag.next_element, NavigableString)
						and isinstance(tag.previous_element, NavigableString))

			for tag in soup.find_all(surrounded_by_strings):
				print tag.name
			# p
			# a
			# a
			# a
			# p
	5.2：find_all()
		现在来了解一下find_all()方法的细节：
		find_all(name,attrs,recursive,string,**kwargs)
		find_all()方法搜索当前tag的所有子节点，(当前为soup对象)，并判断是否符合过滤器的条件，下面分享几个例子
		soup.find_all("title")
		# [<title>The Dormouse's story</title>]

		soup.find_all("p", "title")
		# [<p class="title"><b>The Dormouse's story</b></p>]

		soup.find_all("a")
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
		#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
		#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

		soup.find_all(id="link2")
		# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]

		import re
		soup.find(string=re.compile("sisters"))
		# u'Once upon a time there were three little sisters; and their names were\n'		
		5.2.1：name：
			for tag in soup.find_all("title"):
				print tag
			# [<title>The Dormouse's story</title>]
		5.2.2：keyword参数：
			如果一个指定名字的参数不是搜索内置的参数名，搜索时会把该参数当作指定名字tag的属性搜索，如果包含一个名字为id的参数，Beautiful Soup会搜索每个tag的"id"属性
			soup.find_all(id='link2')
			# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]
			如果传入 href 参数,Beautiful Soup会搜索每个tag的”href”属性:

			soup.find_all(href=re.compile("elsie"))
			# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]
			搜索指定名字的属性时可以使用的参数值包括 字符串 , 正则表达式 , 列表, True .

			下面的例子在文档树中查找所有包含 id 属性的tag,无论 id 的值是什么:

			soup.find_all(id=True)
			# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
			#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
			#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
			使用多个指定名字的参数可以同时过滤tag的多个属性：
			soup.find_all(href=re.compile("elsie"), id='link1')
			# [<a class="sister" href="http://example.com/elsie" id="link1">three</a>]
			但是有些tag属性在搜索时不能使用，比如HTML5中的“data-*”属性：
			data_soup = BeautifulSoup('<div data-foo="value">foo!</div>')
			data_soup.find_all(data-foo="value")
			# SyntaxError: keyword can't be an expression
			但是可以通过find_all()方法的attrs参数定义一个字典来搜索包含特殊属性的tag:
			data_soup.find_all(attrs={"data-foo":"value"})
			# [<div data-foo="value">foo!</div>]
		5.2.3：按CSS搜索
			1:CSS类名的关键字在python中是保留字，用class做参数会导致语法错误，但是可以使用class_参数搜索有指定CSS类名的tag：
			soup.find_all("a",class_="sister")
			# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
			#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
			#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
			2:class_参数接受不同类型的过滤器，字符串，正则表达式，方法或True
			soup.find_all(class_=re.compile("itl"))
			# [<p class="title"><b>The Dormouse's story</b></p>]
			def has_six_characters(css_class):#使用属性值作为方法参数时，使用find_all方法时需要加上属性名=方法
				return css_class is not None and len(css_class) == 6
			soup.find_all(class_=has_six_characters)
			# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
			#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
			#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
			3：tag的class值是多值属性的话，可以通过搜索每一个值
			css_soup = BeautifulSoup('<p class="body strikeout"></p>')
			css_soup.find_all(class_="body")
			# [<p class="body strikeout"></p>]
			css_soup.find_all(class_="strikeout")
			# [<p class="body strikeout"></p>
			也可以按照CSS值完全匹配：
			css_soup.find_all(class_="body strikeout")
			# [<p class="body strikeout"></p>]
			完全匹配class的值时，如果CSS类名的顺序与实际不符，将搜索不到结果：
			soup.find_all("p",atttrs={"class":"sister"})
			# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
			#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
			#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]	
		5.2.4：string参数
			1：string参数可以搜索文档中的字符串内容，与.name参数的可选值一样，.string参数阶段后字符串，正则表达式，列表，True
			soup.find_all(string="Elsie")
			# [u'Elsie']
			soup.find_all(string=["Tillie","Elsie","Lacie"])
			# [u'Elsie',u'Lacie',u'Tillie']
			soup.find_all(string=re.compile("Dormouse"))
			[u'The Dormouse's story',u'The Dormouse's story']
			def is_the_only_string_wuthin_tag(s):
				retutn (s == s.parent.string)
			soup.find_all(is_the_only_string_wuthin_tag)
			# [u"The Dormouse's story", u"The Dormouse's story", u'Elsie', u'Lacie', u'Tillie', u'...']
			2：string参数还可以与其他参数一起联合使用：
			soup.find_all("a",string="Elsie")
			[<a href="http://example.com/elsie" class="sister" id = "link1">Elsie</a>]
		5.2.5：limit参数：
			可以用limit参数限制返回的数量，当搜索到了数量达到limit限制的数量时返回结果
			soup.find_all("a",limit=2)
			# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
			#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]
		5.2.6：recursive参数：
			使用find_all()方法时，Bs会搜索当前tag的所有子孙节点，如果只想搜索当前节点的直接子节点，可以使用recursive=false参数
			以一个简单的文档为例：
				<html>
				 <head>
				  <title>
				   The Dormouse's story
				  </title>
				 </head>
				...
			是否使用recursive参数的搜索结果：
			soup.html.find("title")
			#[<title>The Dormouse's story</title>]
			soup.html.find_all("title",recursive=False)
			# []
			Bs提供的DOM树搜索方法中，都使用了类似的参数定义，但是只有find_all()和find()支持recursive参数
	5.3：想调用find_all()一样调用tag
		find_all()方法几乎是Beautiful Soup中最常用的搜索方法，所以定义了他的简写方法。
		BeautifulSoup对象和tag对象可以被当作一个方法使用，下面两行代码是等价的：
		soup.find_all("a")
		soup("a")
		这两行代码也是等价的
		soup.title.find_all(string=True)
		soup.title(string=True)
	5.4:find()
		find(name,attrs,recursive,string,**kwargs)
		find()防止不返回列表，直接返回结果，且只能返回一个
		soup.find_all("title",limit=1)
		# [<title>The Dormouse's story</title>]
		soup.find("title")
		<title>The Dormouse's story</title>
		find_all()搜索不到结果时返回空列表，而find()返回None
		print(soup.find("hfjkle"))
		None
		
		soup.head.title是tag名字的缩写，该简写的原理就是多次调用当前的find(0方法
		soup.head.title
		<title>The Dormouse's story</title>
		soup.find(head).find(title)
		<title>The Dormouse's story</title>
	5.5：find_parents()和find_parent()
		find_parent()和find_parenta()的参数和find()及find_all()一样
		用来搜索父辈节点
		find_parent直接返回结果，find_parents()返回列表。
		a_string=soup.find(string="Lacie")
		a_string
		u'Lacie'
		a_string.find_parents("a")
		# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]
		a_string.find_parent("p")
		# <p class="story">Once upon a time there were three little sisters; and their names were
		#  <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
		#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a> and
		#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>;
		#  and they lived at the bottom of a well.</p>
		a_string.find_parent("p",class_="title")
		#[]		
	5.6：find_next_siblings()和find_next_sibling()
		此处不讲解，参考.next_sibling和.next_siblings
	5.7：find_previous_siblings()和find_previous_sibling()
		参考.previous_sibling及.previous_siblings
	5.8：find_all_next和find_next
		参考.next_element及.next_elements
	5.9：find_all_previous和find_previous
		参考.previous_elements
	5.10：CSS选择器：
		1:Beautiful Soup支持大部分的CSS选择器，在Tag或BeautifulSoup对象的.select()方法中传入字符串参数，即可使用CSS选择器的语法找到tag
		soup.select("title")
		# [<title>The Dormouse's story</title>]
		soup.select("p nth-of-type(3)")#:nth-of-type(n) 选择器匹配属于父元素的特定类型的第 N 个子元素的每个元素.
		# [<p class="story">...</p>]
		2:通过tag标签逐层查找：
		soup.select(body a)
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
		#  <a class="sister" href="http://example.com/lacie"  id="link2">Lacie</a>,
		#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
		3:找到某个标签的直接子标签：
		soup.select("head > title")
		[<title>The Dormouse's story</title>]
		soup.select("p > a")
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
		#  <a class="sister" href="http://example.com/lacie"  id="link2">Lacie</a>,
		#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
		soup.select("p > a:nth-of-type(2)")
		[<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]
		soup.select("p > #link1") # 选择p标签下的直接id为link1子标签
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
		soup.select<body > a>
		[]
		4:找到兄弟节点标签：
		soup.select("#link1 ~ .sisiter")# 选择id=link1后的class=sister所有兄弟节点标签
		# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
		#  <a class="sister" href="http://example.com/tillie"  id="link3">Tillie</a>]
		soup.select("#link1 + .sister")# 选择id=link1后的class=sister下一个兄弟节点标签
		# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]
		5:通过CSS类名查找：
		soup.select(".sister")# 选择class为sister的标签
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
		#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
		#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
		soup.select("[class~=sister]")# class=sister的所有节点
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
		#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
		#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
		6:通过tag的id查找：
		soup.select("#link1")#选择id为link1的标签
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]

		soup.select("a#link2")#a节点，且id=link2的节点
		# [<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]
		7：同时用多种CSS选择器查询元素：
		soup.select("#link1,#link2")
		soup.select("#link1,#link2")
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
		#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>]
		8：通过是否存在某个属性查找：
		soup.select('a[href]')#所有的a节点有href属性
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
		#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
		#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
		9：通过属性的值查找
		soup.select('a[href="http://example.com/elsie"]')
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]

		soup.select('a[href^="http://example.com/"]')
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
		#  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
		#  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

		soup.select('a[href$="tillie"]')
		# [<a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]

		soup.select('a[href*=".com/el"]')
		# [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>]
		10：通过语言设置来查找：
		multilingual_markup = """
			<p lang="en">Hello</p>
			<p lang="en-us">Howdy, y'all</p>
			<p lang="en-gb">Pip-pip, old fruit</p>
			<p lang="fr">Bonjour mes amis</p>
		"""
		multilingual_soup = BeautifulSoup(multilingual_markup)
		multilingual_soup.select('p[lang]=en')
		# [<p lang="en">Hello</p>,
		#  <p lang="en-us">Howdy, y'all</p>,
		#  <p lang="en-gb">Pip-pip, old fruit</p>]
		返回查到的元素第一个：
		soup.select_one(".sister")
		# <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
6：修改文档树：
Beautiful Soup的强项是对文档的搜索，但同时也可以方便的修改文档树
	6.1：修改tag的名称和属新：
		soup = BeautifulSoup('<b class="boldest">Extremely bold</b>')
		tag = soup.b
		tag.name = "blockquote"
		tag['class'] = "verybold"
		tag['id']=1
		tag
		# <blockquote class="verybold" id="1">Extremely bold</blockquote>
		del tag['class']
		del tag['id']
		tag
		# <blockquote>Extremely bold</blockquote>
	6.2：修改.string:
		markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
		soup = BeautifulSoup(markup)

		tag = soup.a
		tag.string = "New link text."
		tag
		# <a href="http://example.com/">New link text.</a>
		但是需要注意，如果当前tag包含了其他的tag，那么他的.string属性赋值会覆盖掉原有的内容包括子tag(会修改掉当前tag的所有子节点为修改后的值)，谨慎使用
	6.3：append:
		,,,,,,
	